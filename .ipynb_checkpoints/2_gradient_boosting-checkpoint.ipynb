{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f344f160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /opt/conda/lib/python3.11/site-packages (0.47.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from shap) (1.24.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from shap) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from shap) (1.3.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from shap) (2.1.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.11/site-packages (from shap) (4.66.1)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.11/site-packages (from shap) (23.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in /opt/conda/lib/python3.11/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /opt/conda/lib/python3.11/site-packages (from shap) (0.57.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.11/site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from shap) (4.8.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.54->shap) (0.40.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->shap) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->shap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->shap) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ad8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b65213",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab61035",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = pd.read_csv(\"Training_Validation_Test_Datasets/task2_input_train.csv\", index_col=0)\n",
    "input_validate = pd.read_csv(\"Training_Validation_Test_Datasets/task2_input_validate.csv\", index_col=0)\n",
    "input_test = pd.read_csv(\"Training_Validation_Test_Datasets/task2_input_test.csv\", index_col=0)\n",
    "\n",
    "output_train = pd.read_csv(\"Training_Validation_Test_Datasets/task2_output_train.csv\")[\"phq_sum\"]\n",
    "output_validate = pd.read_csv(\"Training_Validation_Test_Datasets/task2_output_validate.csv\")[\"phq_sum\"]\n",
    "output_test = pd.read_csv(\"Training_Validation_Test_Datasets/task2_output_test.csv\")[\"phq_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00fe040",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.01, 0.05, 0.1, 0.2] # learning rate\n",
    "ns = [50, 100, 250, 500] # number of estimators\n",
    "depths = [4,6,8,12] # max depth\n",
    "min_samples = [100,250,500,1000,1500,2000] # min sample split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for lr in lrs:\n",
    "        for n in ns:\n",
    "            for depth in depths:\n",
    "                for min_sample in min_samples:\n",
    "                    params = {\n",
    "                        \"n_estimators\": n,\n",
    "                        \"max_depth\": depth,\n",
    "                        \"min_samples_split\": min_sample,\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"loss\": \"squared_error\",\n",
    "                        \"random_state\": 42\n",
    "                    }\n",
    "\n",
    "                    reg = ensemble.GradientBoostingRegressor(**params)\n",
    "                    reg.fit(input_train, output_train)\n",
    "                    \n",
    "                    y_pred = reg.predict(input_validate)\n",
    "                    mse = round(mean_squared_error(output_validate, y_pred), 4)\n",
    "                    rmse = round(mse ** (1/2), 4)\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"n_estimators\": n,\n",
    "                        \"max_depth\": depth,\n",
    "                        \"min_samples_split\": min_sample,\n",
    "                        \"MSE\": mse,\n",
    "                        \"RMSE\": rmse\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc24ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "best_row = results_df.loc[results_df[\"RMSE\"].idxmin()]\n",
    "best_params = best_row[[\"learning_rate\", \"n_estimators\", \"max_depth\", \"min_samples_split\"]].to_dict()\n",
    "best_rmse = best_row[\"RMSE\"]\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(\"Best Validation RMSE:\", best_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ca9ee",
   "metadata": {},
   "source": [
    "### Feature by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"Grouping_Datasets/Female_Older.csv\", \n",
    "            \"Grouping_Datasets/Female_Younger.csv\", \n",
    "            \"Grouping_Datasets/Male_Older.csv\", \n",
    "            \"Grouping_Datasets/Male_Younger.csv\"]\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 50,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4223cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame(columns=[\"Dataset\", \"MSE\", \"RMSE\"])\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset}...\")\n",
    "    \n",
    "    data = pd.read_csv(dataset, index_col=0)\n",
    "    \n",
    "    X = data.drop(columns=[\"phq_sum\"])\n",
    "    y = data[\"phq_sum\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                        random_state=42)\n",
    "    \n",
    "    gb_model = GradientBoostingRegressor(\n",
    "        learning_rate=param_grid[\"learning_rate\"],\n",
    "        n_estimators=param_grid[\"n_estimators\"],\n",
    "        max_depth=param_grid[\"max_depth\"],\n",
    "        min_samples_split=param_grid[\"min_samples_split\"],\n",
    "        random_state=42)\n",
    "    \n",
    "    gb_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = gb_model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = mse_test ** (1/2) \n",
    "    \n",
    "    \n",
    "    all_results = pd.concat([all_results, pd.DataFrame({\n",
    "        \"Dataset\": [dataset],\n",
    "        \"MSE\": [mse_test],\n",
    "        \"RMSE\": [rmse_test]})], ignore_index=True)\n",
    "    \n",
    "    # SHAP Analysis\n",
    "    explainer = shap.Explainer(gb_model, X_train)\n",
    "    shap_values = explainer(X_test)\n",
    "\n",
    "    # Print SHAP summary plot\n",
    "    shap.summary_plot(shap_values, X_test)\n",
    "    \n",
    "# Print evaluation results\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
